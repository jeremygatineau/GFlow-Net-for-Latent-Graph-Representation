¤ Import and test code from https://github.com/tristandeleu/jax-dag-gflownet/blob/53350bbfba3ab24f9ffa8196a3de42f139d9c5cc/dag_gflownet/env.py#L12
¤ Create agent with inputs DAGs (that will be generated with the GFLOWNet) and that uses that representation to act in the environment
¤ Adapt environment of GFLOWNet for training in this paradigm
¤ Figure out trainig paradigm: bootstrap RL+GLFOWNet with random action, then fine-tune RL+GFLOWnet together, online
¤ Test on Nocture
¤ Implement baseline regular PPO, without DAG generation
¤ Make results 


-----

Issue: in the way this is setup, the DAG will just match the aggregate distribution encoded through the score function, to be able to conditionalize graph generation for observations we can thus include current observation/observation window as an input to the DAG generator. 

Adding backward transitions (removing nodes) would also be useful, as we could start from the last observations' DAG representation as a seed and modify it until we get a graph that matches the new distribution
The problem with backward transitions is that they have to be done in order to not mess up the flow and create disconnected/no flowing DAGs
How, then, do you encode what nodes *can be removed* in the action mask?


So: 
change the gflownet network def to include current observations as an input
understand then change the scoring funcion to be observation-dependent
understand then implement backwards transitions
think through and implement training logic
understand how the 'virtual' gflownet env connects to the true env in which the actor is acting
find a way to represent DAGs for the actor/critic 
maybe, in the fine-tuning phase, the GFN DAG scorer includes a term that comes from the agent's performance in the true env

--> this means that understanding the scoring function is implemented so as to ground DAG generation is very important!!!!!!!!!!
    -> do that first


Weird thing about the score function:
uses local score, by assuming modularity of the reward over edges --> log(r(g)) can be expressed as a sum over local edge contribution
if this is a model of how things ought to be, i.e. imparts a structural bias to the DAG generation then sure, but if this is rather an assumption about the reward structure itself (not how it relate to graphs) then this is more problematic



---------------------------

BGe score is nice but what we need is a way to represent individual observations, 
i.e. reconstruction loss. 

We could also use one good thing about GFlowNets: their ability to generate samples that are proportional to the reward R(G)
This could allow us to generate, say, 10 graphs with the same network, based on the same information that would intrinsically
reflect the belief distribution of *what-could-be-happening-in-the-environment*
this would be a real advantage of GFlownets over other neural net techniqeus

the issues is then to be able to generate those graphs efficiently with the added
constraints that: graph should be determined by each observation and recursive memory
should be taken into account: i.e. we want graph that encompass a running model of the environment state
not just the bayesian structure of the current observation

But this may require the definition of a local score, energy funciton-like estimation
this could be acheived with a kind of critic network for which additivity constraints in enforced
this critic would compute the marginal likelihood of the data given an incomplete graph
it would also have a memory???
